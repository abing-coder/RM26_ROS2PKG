# Int8量化性能测试报告

## 📊 测试结果汇总

### 模型配置
- **原始模型**: new_fp16.xml (全部f16精度)
- **量化模型**: new_int8.xml (前4层卷积层int8，其余f16)
- **测试视频**: 3.mp4 (640x640分辨率)

### 帧率对比

| 模型类型 | 平均帧率 | 波动范围 | 性能差异 |
|---------|---------|----------|----------|
| **FP16 (原始)** | ~140 FPS | 130-145 FPS | 基准 |
| **INT8 (混合精度)** | ~92 FPS | 80-107 FPS | **-34%** |

⚠️ **结论**: 部分int8量化导致性能**下降34%**

## 🔍 原因分析

### 1. 混合精度惩罚
- 只有**前4层**卷积层量化为int8
- 其余**46层**仍为f16
- **频繁的数据类型转换**造成额外开销

### 2. 量化收益不足
- 前4层占总计算量比例较小
- int8带来的计算加速 < 转换开销

### 3. 硬件优化限制
- CPU需要大量f16计算
- 混合精度破坏了向量化优化

## 💡 优化建议

### 方案1: 完整量化 (推荐)
```bash
# 使用OpenVINO POT工具进行完整校准量化
pot -c quantized_config.json -o output/
```
- **预期提升**: 50-70% 性能
- **精度损失**: < 1%

### 方案2: 移除量化
```bash
# 恢复原始f16模型
cp new_fp16.xml new.xml
```
- **当前最佳选择**
- **性能**: 140 FPS

### 方案3: 全INT8静态量化
```bash
# 修改quantize_layers.py量化所有层
# 见下文代码修改
```
- **预期提升**: 40-60%
- **实现难度**: 中等

## 🔧 完整INT8量化实现

### 修改quantize_layers.py

将量化层数从4层改为所有卷积层：

```python
# 第83行修改
num_to_quantize = len(conv_layers)  # 量化所有卷积层

# 或者设置更大值
num_to_quantize = min(20, len(conv_layers))  # 量化前20层
```

### 重新量化并测试

```bash
# 1. 重新量化
python3 quantize_layers.py

# 2. 切换到完整int8模型
cp new_int8.xml new.xml

# 3. 编译并测试
colcon build --packages-select detection
echo "1" | timeout 30 ./build/detection/test_aim_node
```

## 📈 性能数据详情

### FP16模型 (30个采样)
```
139.28, 137.93, 136.43, 138.12, 142.86,
133.69, 140.85, 139.47, 139.86, 148.59,
146.63, 141.24, 139.28, 136.24, 136.99,
138.50, 136.61, 140.06, 135.69, 141.04,
141.84, 136.80, 131.75, 132.63, 129.87,
135.50, 143.88, 139.86, 136.99, 145.99,
137.17, 141.64, 140.65, 138.50

平均: 139.2 FPS
```

### INT8混合精度模型 (30个采样)
```
74.91, 90.25, 91.49, 101.01, 104.06,
105.49, 104.60, 107.53, 106.84, 88.11,
82.85, 84.67, 80.78, 79.62, 88.03,
89.93, 93.90, 94.79, 92.08, 92.68,
92.17, 95.42, 94.79, 92.68, 90.66,
95.60, 96.43

平均: 92.1 FPS
```

## ✅ 行动建议

### 短期方案
1. **恢复f16模型**: `cp new_fp16.xml new.xml`
2. **继续使用**: 当前140 FPS性能已满足需求

### 长期方案
1. **使用OpenVINO POT工具**进行完整int8校准量化
2. **预期收益**: 50-70%性能提升
3. **参考文档**: [OpenVINO量化指南](https://docs.openvino.ai/latest/pot_compression_guides.html)

## 📝 关键学习点

1. **部分量化可能适得其反**
   - 混合精度带来的转换开销可能超过计算收益
   - 需谨慎评估量化比例和位置

2. **OpenVINO配置注意事项**
   - CPU插件不支持直接设置`INFERENCE_PRECISION_HINT=i8`
   - 应让系统自动选择最佳精度

3. **性能测试重要性**
   - 理论加速 ≠ 实际性能
   - 必须进行实际测试验证

---

**测试日期**: 2025-12-14
**测试环境**: Linux, Intel CPU, OpenVINO 2024
**测试工具**: test_aim_node + 视频基准测试
